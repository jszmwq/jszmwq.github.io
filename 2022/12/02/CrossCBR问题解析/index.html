<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>CrossCBR问题解析 | j52nnw9的博客</title><meta name="keywords" content="论文"><meta name="author" content="萌新QAQ"><meta name="copyright" content="萌新QAQ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation一、标题：捆绑推荐中的跨视图对比学习视图是如何体现“跨”字的，视图之间是怎样“对比”的 视图是如何体现“跨”字的本文中含有两个视图，分别为包视图和物品视图 包视图直接通过用户-包图表的交互体现针对用户的捆绑包推荐 物品视图以物品作为粒度描述连接用户-物品图表和包-物">
<meta property="og:type" content="article">
<meta property="og:title" content="CrossCBR问题解析">
<meta property="og:url" content="https://jszmwq.github.io/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/index.html">
<meta property="og:site_name" content="j52nnw9的博客">
<meta property="og:description" content="CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation一、标题：捆绑推荐中的跨视图对比学习视图是如何体现“跨”字的，视图之间是怎样“对比”的 视图是如何体现“跨”字的本文中含有两个视图，分别为包视图和物品视图 包视图直接通过用户-包图表的交互体现针对用户的捆绑包推荐 物品视图以物品作为粒度描述连接用户-物品图表和包-物">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://jszmwq.github.io/img/Animation/9.jpeg">
<meta property="article:published_time" content="2022-12-02T03:40:07.000Z">
<meta property="article:modified_time" content="2023-04-23T09:52:52.061Z">
<meta property="article:author" content="萌新QAQ">
<meta property="article:tag" content="论文">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jszmwq.github.io/img/Animation/9.jpeg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://jszmwq.github.io/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CrossCBR问题解析',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-23 17:52:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/image.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/Animation/9.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">j52nnw9的博客</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CrossCBR问题解析</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-12-02T03:40:07.000Z" title="发表于 2022-12-02 11:40:07">2022-12-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-23T09:52:52.061Z" title="更新于 2023-04-23 17:52:52">2023-04-23</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CrossCBR问题解析"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="CrossCBR-Cross-view-Contrastive-Learning-for-Bundle-Recommendation"><a href="#CrossCBR-Cross-view-Contrastive-Learning-for-Bundle-Recommendation" class="headerlink" title="CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation"></a>CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation</h2><h3 id="一、标题：捆绑推荐中的跨视图对比学习"><a href="#一、标题：捆绑推荐中的跨视图对比学习" class="headerlink" title="一、标题：捆绑推荐中的跨视图对比学习"></a>一、标题：捆绑推荐中的跨视图对比学习</h3><h4 id="视图是如何体现“跨”字的，视图之间是怎样“对比”的"><a href="#视图是如何体现“跨”字的，视图之间是怎样“对比”的" class="headerlink" title="视图是如何体现“跨”字的，视图之间是怎样“对比”的"></a>视图是如何体现“跨”字的，视图之间是怎样“对比”的</h4><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202115216395.png" alt="image-20221202115216395"></p>
<h4 id="视图是如何体现“跨”字的"><a href="#视图是如何体现“跨”字的" class="headerlink" title="视图是如何体现“跨”字的"></a>视图是如何体现“跨”字的</h4><p>本文中含有两个视图，分别为包视图和物品视图</p>
<p>包视图直接通过用户-包图表的交互体现针对用户的捆绑包推荐</p>
<p>物品视图以物品作为粒度描述连接用户-物品图表和包-物品图表，间接描述用户对包偏好</p>
<p>最后得到模型预测表示为$y=e^{B^T}_ue^B_b+e^{I^T}_ue^I_b$</p>
<h4 id="现有方法的不足"><a href="#现有方法的不足" class="headerlink" title="现有方法的不足"></a>现有方法的不足</h4><p>BundleNet算法盲目地将两个视图合并为一个统一的三方图，采用没有差异化的统⼀视图。无法从这两种视图中区分用户之间的行为相似性和包之间的内容关联性，从而模糊了它们之间的联系。</p>
<p>BGCN算法分别对包视图和物品视图执行表征学习和偏好预测，然后融合这两个特定于视图的预测。但它只考虑了预测级别的合作信号，而不是直接将这种信号插入到为推荐而优化的表征中。</p>
<h4 id="视图之间是怎样“对比”的"><a href="#视图之间是怎样“对比”的" class="headerlink" title="视图之间是怎样“对比”的"></a>视图之间是怎样“对比”的</h4><p>在模型损失优化上，采用了InfoNCE对比损失和BPR loss(贝叶斯个性化排序损失)，对比主要体现在InfoNCE对比损失上。</p>
<h3 id="二、LightGCN"><a href="#二、LightGCN" class="headerlink" title="二、LightGCN"></a>二、LightGCN</h3><h4 id="在NGCF上改进"><a href="#在NGCF上改进" class="headerlink" title="在NGCF上改进"></a>在NGCF上改进</h4><p>在将用户和项目从ID嵌入成向量后，然后利用用户-项目二部图来进行传播，NGCF的传播算法如下</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203015532714.png" alt="image-20221203015532714"></p>
<p>其中$e_u^{(k)}$和$e_i^{(k)}$分别表示在k层传播后用户u和项目i的嵌入，k表示传播的层数。$N_u$表示用户节点u交互过的邻域项目集，$N_i$表示项目节点i交互过的邻域用户集。σ表示非线性激活函数，W1和W2是训练的权重矩阵。</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203021514568.png" alt="image-20221203021514568"></p>
<ul>
<li>NGCF-f，它删除了特征转换矩阵W1和W2。</li>
<li>NGCF-n，它消除了非线性激活函数σ。</li>
<li>NGCF-fn，它删除了两个特征转换矩阵和非线性激活函数。</li>
</ul>
<p>可以看到NGCF-fn的召回率和loss都有明显改善。特征转换矩阵和非线性激活函数对最终结果影响不大，性能反而有所下降。</p>
<p>NGCF 是一个用于协同过滤的繁重的 GCN 模型，而GCN的基本思想是通过平滑图上的特征来学习节点的表示。 为了实现这一点，它迭代地执行图卷积，即，将邻居的特征聚合为目标节点的新表示。 这种邻域聚合可以抽象为：<br>$$<br>e_u^{(k+1)}=AGG(e_u^{(k)},e_i^{(k)}:i∈N_u)<br>$$<br>AGG是一个聚合函数（图形卷积的核心），它考虑了目标节点及其邻居节点的第k层表示形式。</p>
<p>很多工作将AGG特殊化，例如GIN 中的加权和聚合器，GraphSAGE中的LSTM聚合器和BGNN中的双线性交互聚合器等。</p>
<p>但是，大多数工作都将AGG函数与特征转换或非线性激活功能联系起来。 尽管它们在具有语义输入功特征的节点或图分类任务上表现良好，但是它们对于协作过滤可能很繁琐。</p>
<h4 id="LightGCN模型图"><a href="#LightGCN模型图" class="headerlink" title="LightGCN模型图"></a>LightGCN模型图</h4><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202141922544.png" alt="image-20221202141922544"></p>
<h5 id="LightGCN模型的总体思路"><a href="#LightGCN模型的总体思路" class="headerlink" title="LightGCN模型的总体思路"></a>LightGCN模型的总体思路</h5><p>(1)先将用户和项目节点的邻域聚合</p>
<p>(2)使用三层卷积层分别生成每层的嵌入</p>
<p>(3)将节点的原始输入与生成每层新的嵌入做一个加权和</p>
<p>(4)将用户和项目最终的生成节点表示做内积生成预测的分数</p>
<h5 id="Light-Graph-Convolution轻型图卷积"><a href="#Light-Graph-Convolution轻型图卷积" class="headerlink" title="Light Graph Convolution轻型图卷积"></a>Light Graph Convolution轻型图卷积</h5><p>LightGCN中，采用简单的加权和聚合器，放弃了特征变换和非线性激活的使用。只聚合已连接的邻居，而不集成目标节点本身（自连接）。LightGCN中的轻型图卷积运算（也称为传播规则）定义如下</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203024610326.png" alt="image-20221203024610326"></p>
<p>对称归一化项$\frac{1}{\sqrt{|N_u|}\sqrt{|N_i|}}$遵循标准GCN的设计,可以避免嵌入的规模随着图卷积操作的增加而增加。</p>
<h5 id="层组合和模型预测"><a href="#层组合和模型预测" class="headerlink" title="层组合和模型预测"></a>层组合和模型预测</h5><p>在LGCN中，唯一可训练的模型参数就是第0层的嵌入，即为所有用户的$e^{(0)}_{u}$和所有项的$e^{(0)}_i$。当第0层被给定后，通过轻量图卷积公式计算高层嵌入。在k层LGC之后，我们进一步组合在每个层上获得的嵌入，以形成用户（项）的最终表示。</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203030410457.png" alt="image-20221203030410457"></p>
<p>其中，$α_k≥0$表示第k层嵌入在构成最终嵌入中的重要度。可以将其视为要调整优化的超参数，发现将$α_k$统一设置为$\frac{1}{K+1}$通常可获得良好的性能，使其保持简单性。</p>
<p>采用图层组合的原因</p>
<p>（1）随着层数的增加，嵌入会变得更加平滑。因此，仅使用最后一层是有问题的。</p>
<p>（2）不同层的嵌入具有不同的语义。 例如，第一层对具有交互作用的用户和项目强制执行平滑操作，第二层对在交互的项（用户）上重叠的用户（项目）进行平滑操作，更高的层则捕获较高级别的邻近度。因此，将它们结合起来将使表示更加全面。</p>
<p>（3）将不同层的嵌入与加权和结合起来，可以捕获图卷积和自连接的效果。</p>
<h5 id="模型预测定义为用户和项目最终表示的内积，作为推荐生成的排名："><a href="#模型预测定义为用户和项目最终表示的内积，作为推荐生成的排名：" class="headerlink" title="模型预测定义为用户和项目最终表示的内积，作为推荐生成的排名："></a>模型预测定义为用户和项目最终表示的内积，作为推荐生成的排名：</h5><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203031235355.png" alt="image-20221203031235355"></p>
<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203032255699.png" alt="image-20221203032255699" style="zoom: 80%;">

<h4 id="矩阵形式："><a href="#矩阵形式：" class="headerlink" title="矩阵形式："></a>矩阵形式：</h4><p>令用户-项目交互矩阵为$R=R^{M×N}$，其中M,N分别表示用户和物品的数量。如果u与i交互，则每个项(entry) $R_{ui}$为 1，否则为0。然后我们得到用户-项目邻接矩阵为:</p>
<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203032927906.png" alt="image-20221203032927906" style="zoom:80%;">

<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203205944351.png" alt="image-20221203205944351" style="zoom:80%;">

<p>令第0层的嵌入矩阵为$E^{(0)}∈R^{(M+N)<em>T}$，T为嵌入大小<br>$$<br>E^{(k+1)} = (D^{−\frac{1}{2}}AD^{−\frac{1}{2}})E^{(k)}<br>$$<br>D为(M+N)</em>(M+N)维矩阵，其中$D_{ii}$的值为邻接矩阵A（也称为度矩阵）的第i行向量中的非零项的数目。其中<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203195020350.png" alt="image-20221203195020350" style="zoom: 80%;">为归一化矩阵。</p>
<p>最后，我们得到用于模型预测的最终嵌入矩阵为：</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203195105042.png" alt="image-20221203195105042"></p>
<p> α是学习层组合系数</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203210217831.png" alt="image-20221203210217831"></p>
<blockquote>
<p>我们以下图的用户-物品交互图为例</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203202737785.png" alt="image-20221203202737785"></p>
<p>根据构造规则，得到用户-项目邻接矩阵A为</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203202938332.png" alt="image-20221203202938332"></p>
<p>根据A中每行非零项的数目，得到矩阵D为</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203203116996.png" alt="image-20221203203116996"></p>
<p>则归一化矩阵<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203203144272.png" alt="image-20221203203144272" style="zoom:80%;">为</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221203203211336.png" alt="image-20221203203211336"></p>
<p>（目前还不会将矩阵形式和图卷积运算联系起来）</p>
</blockquote>
<h3 id="三、InfoNCE-loss对比损失"><a href="#三、InfoNCE-loss对比损失" class="headerlink" title="三、InfoNCE loss对比损失"></a>三、InfoNCE loss对比损失</h3><p>对比学习损失函数有多种，其中比较常用的一种是InfoNCE loss。</p>
<h4 id="InfoNCE-loss公式"><a href="#InfoNCE-loss公式" class="headerlink" title="InfoNCE loss公式"></a>InfoNCE loss公式</h4><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202132616359.png" alt="image-20221202132616359"></p>
<p>其中的q和k可以表示为其他的形式，比如相似度度量，余弦相似度等。分子部分表示正例之间的相似度，分母表示正例与负例之间的相似度，因此，相同类别相似度越大，不同类别相似度越小，损失就会越小。</p>
<h5 id="与交叉熵损失对比"><a href="#与交叉熵损失对比" class="headerlink" title="与交叉熵损失对比"></a>与交叉熵损失对比</h5><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202133935711.png" alt="image-20221202133935711"></p>
<p>上式中的k在有监督学习里指的是数据集的总类别数，如CV的ImageNet数据集有1000类，k就是1000。但如果通过使用数据增强手段产生对比学习正样本对，有多少张图就有多少类，会导致计算复杂度非常高。</p>
<p>而在对比学习InfoNCE loss里，这个k指的是负样本的数量。InfoNCE loss公式分母中的sum是在1个正样本和k个负样本上做的，从0到k，所以共k+1个样本，</p>
<h5 id="对NCE-Loss对比"><a href="#对NCE-Loss对比" class="headerlink" title="对NCE Loss对比"></a>对NCE Loss对比</h5><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202134006713.png" alt="image-20221202134006713"></p>
<p>InfoNCE loss是基于对比度的一个损失函数，是由NCE Loss损失函数演变而来。NCE Loss损失函数是基于采样的方法，将多分类问题转为二分类问题，分为数据类别和噪声类别。正样本标值为1，负样本标值为0。 Info NCE loss作为NCE的一个简单变体，演变成一个多分类问题。</p>
<h4 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h4><p>论文MoCo提出，我们可以把对比学习看成是一个字典查询的任务，即训练一个编码器从而去做字典查询的任务。假设已经有一个编码好的query q（一个特征），以及一系列编码好的样本k0,k1,k2,…，那么k0,k1,k2,…可以看作是字典里的key。假设字典里只有一个key即k+(称为k positive）是跟q是匹配的，那么q和k+就互为正样本对，其余的key为q的负样本。一旦定义好了正负样本对，就需要一个对比学习的损失函数来指导模型来进行学习。这个损失函数需要满足这些要求，即当query q和唯一的正样本k+相似，并且和其他所有负样本key都不相似的时候，这个loss的值应该比较低。反之，如果q和k+不相似，或者q和其他负样本的key相似了，那么loss就应该大，从而惩罚模型，促使模型进行参数更新。</p>
<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202132009971.png" alt="image-20221202132009971" style="zoom:50%;">

<p>一个好的对比学习应该具备以下两个属性：Alignment和Uniformity。</p>
<p>Alignment（对齐）指的是相似的例子，也就是正例，映射到单位超球面后，应该具有比较接近的特征，球面距离应该比较近；</p>
<p>Uniformity（均匀性）指的是系统应该倾向于应该在特征里保留尽可能多的信息，映射到球面上就要求，单位球面上的特征应该尽可能地均与分布在球面上，<strong>分布越均匀，意味着保留的特征也就越多越充分。</strong>因为，分布越均匀，意味着各自保留各自的独有的特征，这代表着信息保留越充分。</p>
<p>Uniformity特性的极端反例，所有数据都映射到单位超球面的同一个点上，这代表着所有数据的信息都被丢掉，体现为数据分布极度不均匀得到了超球面上的同一个点。也就意味着，所有数据经过两次非线性计算之后都收敛到同一个常数上，这种异常情况我们称之为：模型坍塌（collapse），如下图所示。</p>
<img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202134816884.png" alt="image-20221202134816884" style="zoom:50%;">

<p>在公式中可知，分子中的S（）体现出了Alignment属性，它期望在超球面上正例之间的距离越近越好；分母中的S（）则体现了Uniformity属性，它期望在负例对之间的距离尽可能的远，这种推力会尽量将点尽可能地均匀分布在超球面上，保留了尽可能多的有用信息。损失函数inforNCE会在Alignment和Uniformity之间寻找折中点。如果只有Alignment模型会很快坍塌到常数，所以损失函数中采用负例的对比学习计算方法，主要是靠负例的Uniformity来防止模型坍塌。</p>
<h4 id="温度系数τ"><a href="#温度系数τ" class="headerlink" title="温度系数τ"></a>温度系数τ</h4><p>温度系数τ针对负例难度。在对比学习中，对于数据x，除了他的唯一正例x+外，所有其他的数据都是负例。这些负例有一些和x比较像，有一些差异比较大，对于比较接近原始数据特征，导致区分难度比较大。会导致比较像的、有难度的负例在超球面上距离比较近，比较容易区分的在超球面上距离比较远。</p>
<p>温度参数T起到的作用：温度参数会将模型更新的重点，聚焦到有难度的负例，并对他们做相应的惩罚，难度越大，也即与x越接近，分配到的惩罚系数越多。所谓惩罚就是，就是在模型优化的过程中，距离越近的负例易获得更多的权重，会具有更大的斥力将其推远。</p>
<p>温度系数是设定的超参数，它的作用是控制模型对负样本的区分度。温度系数设的越大，q*k的分布变得越平滑，那么对比损失会对所有的负样本一视同仁，导致模型学习没有轻重。如果温度系数设的过小，则模型会越关注特别困难的负样本，但其实那些负样本很可能是潜在的正样本，这样会导致模型很难收敛或者泛化能力差。因此温度系数的设定是不可或缺的。</p>
<h3 id="四、BPR-loss贝叶斯个性化排序损失"><a href="#四、BPR-loss贝叶斯个性化排序损失" class="headerlink" title="四、BPR loss贝叶斯个性化排序损失"></a>四、BPR loss贝叶斯个性化排序损失</h3><p>设计这个损失函数的最主要的目标是：未来正边的计分函数结果是一个较大的数字，而未来负边的计分函数结果是一个较小的数字。所以结合这两个问题的一个比较好的方法是：希望用户u的给定未来正边和用户u的给定未来负边之间的差值是一个较大的数字:</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/641.png" alt="图片"></p>
<p>在使用 sigmoid 函数将两个分数的差异映射到区间 [0, 1]后，就能够将分数视为概率。因此对于一个给定用户u，可以将给定的所有正边和负边对的分数组合起来输入损失函数中。然后在所有用户中平均这些损失以获得最终的损失，这称为贝叶斯个性化排名 (Bayesian Personalized Ranking BPR) 损失</p>
<h4 id="排序推荐算法背景"><a href="#排序推荐算法背景" class="headerlink" title="排序推荐算法背景"></a>排序推荐算法背景</h4><p>排序推荐算法历史很悠久，早在做信息检索的各种产品中就已经在使用了。</p>
<p>最早的第一类排序算法类别是点对方法(Pointwise Approach)，这类算法将排序问题被转化为分类、回归之类的问题，并使用现有分类、回归等方法进行实现。</p>
<p>第二类排序算法是成对方法(Pairwise Approach)，在序列方法中，排序被转化为对序列分类或对序列回归。所谓的pair就是成对的排序，比如(a,b)一组表明a比b排的靠前。我们要讲到的BPR就属于这一类。</p>
<p>第三类排序算法是列表方法(Listwise Approach)，它采用更加直接的方法对排序问题进行了处理。它在学习和预测过程中都将排序列表作为一个样本。排序的组结构被保持。</p>
<h4 id="BPR建模思路"><a href="#BPR建模思路" class="headerlink" title="BPR建模思路"></a>BPR建模思路</h4><p>在BPR算法中，我们将任意用户u对应的物品进行标记，如果用户u在同时有物品i和j的时候点击了i，那么我们就得到了一个三元组$&lt;u,i,j&gt;&lt;u,i,j&gt;$，它表示对用户u来说，i的排序要比j靠前。如果对于用户u来说我们有m组这样的反馈，那么我们就可以得到m组用户u对应的训练样本。</p>
<p>既然是基于贝叶斯，那么我们也就有假设，这里的假设有两个：一是每个用户之间的偏好行为相互独立，即用户u在商品i和j之间的偏好和其他用户无关。二是同一用户对不同物品的偏序相互独立，也就是用户u在商品i和j之间的偏好和其他的商品无关。为了便于表述，我们用&gt;u&gt;u符号表示用户u的偏好，上面的&lt;u,i,j&gt;&lt;u,i,j&gt;可以表示为：$i&gt;_uj$。</p>
<p>在BPR中，这个排序关系符号&gt;u&gt;u满足完全性，反对称性和传递性，即对于用户集U和物品集I：</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202140621607.png" alt="image-20221202140621607"></p>
<p>同时，BPR也用了和funkSVD类似的矩阵分解模型，这里BPR对于用户集U和物品集I的对应的U×I的预测排序矩阵$X^¯$，我们期望得到两个分解后的用户矩阵W(|U|×k)和物品矩阵H(|I|×k)，满足<br>$$<br>X^¯=WH^T<br>$$<br>这里的k和funkSVD类似，也是自己定义的，一般远远小于|U|,|I|。由于BPR是基于用户维度的，所以对于任意一个用户u，对应的任意一个物品i我们期望有：</p>
<p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202141122404.png" alt="image-20221202141122404"></p>
<h4 id="BPR公式"><a href="#BPR公式" class="headerlink" title="BPR公式"></a>BPR公式</h4><p><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202141528681.png" alt="image-20221202141528681"></p>
<h3 id="五、Data-augmentation数据增强"><a href="#五、Data-augmentation数据增强" class="headerlink" title="五、Data augmentation数据增强"></a>五、Data augmentation数据增强</h3><h3 id="六、模型图分析"><a href="#六、模型图分析" class="headerlink" title="六、模型图分析"></a>六、模型图分析</h3><img src="/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/image-20221202124356975.png" alt="image-20221202124356975">
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">萌新QAQ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://jszmwq.github.io/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/">https://jszmwq.github.io/2022/12/02/CrossCBR%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://jszmwq.github.io" target="_blank">j52nnw9的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a></div><div class="post_share"><div class="social-share" data-image="/img/Animation/9.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/02/%E5%90%8C%E6%9E%84%E7%BD%91%E7%BB%9C%E5%8F%AF%E5%88%86%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E9%97%AE%E9%A2%98/"><img class="prev-cover" src="/img/Animation/1.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">同构网络可分任务调度问题</div></div></a></div><div class="next-post pull-right"><a href="/2022/11/22/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96%E5%BB%BA%E6%A8%A1%E4%B8%8E%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"><img class="next-cover" src="/img/Animation/5.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大数据优化建模与算法笔记</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/image.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">萌新QAQ</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">51</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#CrossCBR-Cross-view-Contrastive-Learning-for-Bundle-Recommendation"><span class="toc-number">1.</span> <span class="toc-text">CrossCBR: Cross-view Contrastive Learning for Bundle Recommendation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A0%87%E9%A2%98%EF%BC%9A%E6%8D%86%E7%BB%91%E6%8E%A8%E8%8D%90%E4%B8%AD%E7%9A%84%E8%B7%A8%E8%A7%86%E5%9B%BE%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.1.</span> <span class="toc-text">一、标题：捆绑推荐中的跨视图对比学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%86%E5%9B%BE%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%93%E7%8E%B0%E2%80%9C%E8%B7%A8%E2%80%9D%E5%AD%97%E7%9A%84%EF%BC%8C%E8%A7%86%E5%9B%BE%E4%B9%8B%E9%97%B4%E6%98%AF%E6%80%8E%E6%A0%B7%E2%80%9C%E5%AF%B9%E6%AF%94%E2%80%9D%E7%9A%84"><span class="toc-number">1.1.1.</span> <span class="toc-text">视图是如何体现“跨”字的，视图之间是怎样“对比”的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%86%E5%9B%BE%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%93%E7%8E%B0%E2%80%9C%E8%B7%A8%E2%80%9D%E5%AD%97%E7%9A%84"><span class="toc-number">1.1.2.</span> <span class="toc-text">视图是如何体现“跨”字的</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E6%96%B9%E6%B3%95%E7%9A%84%E4%B8%8D%E8%B6%B3"><span class="toc-number">1.1.3.</span> <span class="toc-text">现有方法的不足</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%86%E5%9B%BE%E4%B9%8B%E9%97%B4%E6%98%AF%E6%80%8E%E6%A0%B7%E2%80%9C%E5%AF%B9%E6%AF%94%E2%80%9D%E7%9A%84"><span class="toc-number">1.1.4.</span> <span class="toc-text">视图之间是怎样“对比”的</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81LightGCN"><span class="toc-number">1.2.</span> <span class="toc-text">二、LightGCN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9C%A8NGCF%E4%B8%8A%E6%94%B9%E8%BF%9B"><span class="toc-number">1.2.1.</span> <span class="toc-text">在NGCF上改进</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LightGCN%E6%A8%A1%E5%9E%8B%E5%9B%BE"><span class="toc-number">1.2.2.</span> <span class="toc-text">LightGCN模型图</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#LightGCN%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%80%BB%E4%BD%93%E6%80%9D%E8%B7%AF"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">LightGCN模型的总体思路</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Light-Graph-Convolution%E8%BD%BB%E5%9E%8B%E5%9B%BE%E5%8D%B7%E7%A7%AF"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">Light Graph Convolution轻型图卷积</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B1%82%E7%BB%84%E5%90%88%E5%92%8C%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">层组合和模型预测</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%AE%9A%E4%B9%89%E4%B8%BA%E7%94%A8%E6%88%B7%E5%92%8C%E9%A1%B9%E7%9B%AE%E6%9C%80%E7%BB%88%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%86%85%E7%A7%AF%EF%BC%8C%E4%BD%9C%E4%B8%BA%E6%8E%A8%E8%8D%90%E7%94%9F%E6%88%90%E7%9A%84%E6%8E%92%E5%90%8D%EF%BC%9A"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">模型预测定义为用户和项目最终表示的内积，作为推荐生成的排名：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F%EF%BC%9A"><span class="toc-number">1.2.3.</span> <span class="toc-text">矩阵形式：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81InfoNCE-loss%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.3.</span> <span class="toc-text">三、InfoNCE loss对比损失</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#InfoNCE-loss%E5%85%AC%E5%BC%8F"><span class="toc-number">1.3.1.</span> <span class="toc-text">InfoNCE loss公式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%AF%B9%E6%AF%94"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">与交叉熵损失对比</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9NCE-Loss%E5%AF%B9%E6%AF%94"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">对NCE Loss对比</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%90%86%E8%A7%A3"><span class="toc-number">1.3.2.</span> <span class="toc-text">理解</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B8%A9%E5%BA%A6%E7%B3%BB%E6%95%B0%CF%84"><span class="toc-number">1.3.3.</span> <span class="toc-text">温度系数τ</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E3%80%81BPR-loss%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%92%E5%BA%8F%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.4.</span> <span class="toc-text">四、BPR loss贝叶斯个性化排序损失</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E8%83%8C%E6%99%AF"><span class="toc-number">1.4.1.</span> <span class="toc-text">排序推荐算法背景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BPR%E5%BB%BA%E6%A8%A1%E6%80%9D%E8%B7%AF"><span class="toc-number">1.4.2.</span> <span class="toc-text">BPR建模思路</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BPR%E5%85%AC%E5%BC%8F"><span class="toc-number">1.4.3.</span> <span class="toc-text">BPR公式</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%94%E3%80%81Data-augmentation%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">1.5.</span> <span class="toc-text">五、Data augmentation数据增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%A8%A1%E5%9E%8B%E5%9B%BE%E5%88%86%E6%9E%90"><span class="toc-number">1.6.</span> <span class="toc-text">六、模型图分析</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/06/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C%E5%9B%9B/" title="操作系统上机实验四"><img src="/img/Animation/4.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统上机实验四"/></a><div class="content"><a class="title" href="/2022/06/02/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8A%E6%9C%BA%E5%AE%9E%E9%AA%8C%E5%9B%9B/" title="操作系统上机实验四">操作系统上机实验四</a><time datetime="2023-04-23T09:53:46.388Z" title="更新于 2023-04-23 17:53:46">2023-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/31/%E8%87%AA%E9%80%82%E5%BA%94%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" title="自适应遗传算法"><img src="/img/Animation/3.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="自适应遗传算法"/></a><div class="content"><a class="title" href="/2022/12/31/%E8%87%AA%E9%80%82%E5%BA%94%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/" title="自适应遗传算法">自适应遗传算法</a><time datetime="2023-04-23T09:52:52.278Z" title="更新于 2023-04-23 17:52:52">2023-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E4%B8%8A%E6%9C%BA%E9%A2%98%E7%9B%AE/" title="计算机图形学上机题目"><img src="/img/Animation/4.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机图形学上机题目"/></a><div class="content"><a class="title" href="/2023/01/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6%E4%B8%8A%E6%9C%BA%E9%A2%98%E7%9B%AE/" title="计算机图形学上机题目">计算机图形学上机题目</a><time datetime="2023-04-23T09:52:52.278Z" title="更新于 2023-04-23 17:52:52">2023-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/01/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/" title="计算机图形学"><img src="/img/Animation/5.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机图形学"/></a><div class="content"><a class="title" href="/2023/01/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/" title="计算机图形学">计算机图形学</a><time datetime="2023-04-23T09:52:52.278Z" title="更新于 2023-04-23 17:52:52">2023-04-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/12/22/%E8%AE%A1%E7%BB%84%E8%AF%BE%E8%AE%BE/" title="计组课设"><img src="/img/Animation/2.webp" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计组课设"/></a><div class="content"><a class="title" href="/2022/12/22/%E8%AE%A1%E7%BB%84%E8%AF%BE%E8%AE%BE/" title="计组课设">计组课设</a><time datetime="2023-04-23T09:52:52.278Z" title="更新于 2023-04-23 17:52:52">2023-04-23</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By 萌新QAQ</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/mouse_snow.min.js"></script> <script src="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/js/hideMobileSidebar.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>